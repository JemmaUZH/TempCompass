{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhxjCi3oR-UN"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gkEUqOPSl0y"
      },
      "outputs": [],
      "source": [
        "# Fetch the discovery docs for the Generative Language API service.\n",
        "from googleapiclient.discovery import build\n",
        "import googleapiclient\n",
        "import requests\n",
        "\n",
        "DISCOVERY_URL = f'https://generativelanguage.googleapis.com/$discovery/rest?version=v1beta&key={GOOGLE_API_KEY}';\n",
        "discovery_docs = requests.get(DISCOVERY_URL).content\n",
        "genai_service = googleapiclient.discovery.build_from_document(discovery_docs, developerKey=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4hJCekGKmto",
        "outputId": "f9e7be65-527b-4e99-bedd-0f39943f959e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3x4x1_FUEmW"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Create or cleanup existing extracted image frames directory.\n",
        "FRAME_PREFIX = \"_frame\"\n",
        "def create_frame_output_dir(output_dir):\n",
        "  if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "  else:\n",
        "    shutil.rmtree(output_dir)\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "def extract_frame_from_video(vfile, frame_path):\n",
        "  vid = os.path.basename(vfile).replace('.mp4', '')\n",
        "  frame_path = f\"{frame_path}/{vid}\"\n",
        "  if os.path.exists(frame_path):\n",
        "    return\n",
        "  print(f\"Extracting {vfile} at 1 frame per second. This might take a bit...\")\n",
        "  create_frame_output_dir(frame_path)\n",
        "  vidcap = cv2.VideoCapture(vfile)\n",
        "  fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "  output_file_prefix = os.path.basename(vfile).replace('.', '_')\n",
        "  success,image = vidcap.read()\n",
        "  frame_count = 0  # Initialize a frame counter\n",
        "  count = 0\n",
        "  while vidcap.isOpened():\n",
        "      success, frame = vidcap.read()\n",
        "      if not success:  # End of video\n",
        "          break\n",
        "      if count % int(fps) == 0:  # Extract a frame every second\n",
        "          image_name = f\"{output_file_prefix}{FRAME_PREFIX}{frame_count:04d}.jpg\"\n",
        "          output_filename = os.path.join(frame_path, image_name)\n",
        "          cv2.imwrite(output_filename, frame)\n",
        "          frame_count += 1\n",
        "      count += 1\n",
        "  vidcap.release()  # Release the capture object\n",
        "  print(f\"Completed video frame extraction!\\n\\nExtracted: {frame_count} frames\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pBznGYsUgfV"
      },
      "outputs": [],
      "source": [
        "import mimetypes\n",
        "import os\n",
        "\n",
        "class File:\n",
        "  def __init__(self, file_path: str, display_name: str = None,\n",
        "               timestamp_seconds: int = None, mimetype: str = None, uri = None):\n",
        "    self.file_path = file_path\n",
        "    if display_name:\n",
        "      self.display_name = display_name\n",
        "    if timestamp_seconds != None:\n",
        "      self.timestamp = seconds_to_time_string(timestamp_seconds)\n",
        "    # Detect mimetype if not specified\n",
        "    self.mimetype = mimetype if mimetype else mimetypes.guess_type(file_path)[0]\n",
        "    self.uri = uri\n",
        "\n",
        "  def set_file_uri(self, uri):\n",
        "    self.uri = uri\n",
        "\n",
        "def seconds_to_time_string(seconds):\n",
        "  \"\"\"Converts an integer number of seconds to a string in the format '00:00'.\n",
        "     Format is the expected format for Gemini 1.5.\n",
        "  \"\"\"\n",
        "  minutes = seconds // 60\n",
        "  seconds = seconds % 60\n",
        "  return f\"{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "def get_timestamp_seconds(filename):\n",
        "  \"\"\"Extracts the frame count (as an integer) from a filename with the format\n",
        "     'output_file_prefix_frame0000.jpg'.\n",
        "  \"\"\"\n",
        "  parts = filename.split(FRAME_PREFIX)\n",
        "  if len(parts) != 2:\n",
        "      return None  # Indicate that the filename might be incorrectly formatted\n",
        "\n",
        "  frame_count_str = parts[1].split(\".\")[0]\n",
        "  return int(frame_count_str)\n",
        "\n",
        "def delete_upload_files(uploaded_files):\n",
        "  # Delete the files with its resource name\n",
        "  print(f'Deleting {len(uploaded_files)} images. This might take a bit...')\n",
        "  for file in uploaded_files:\n",
        "    resource = file.uri.split(\"/files/\")[-1]\n",
        "    response = genai_service.files().delete(name=f\"files/{resource}\").execute()\n",
        "    # print(f'Deleted {file.file_path} as URI {file.uri}')\n",
        "\n",
        "  print(f\"Completed deleting files!\\n\\nDeleted: {len(uploaded_files)} files\")\n",
        "\n",
        "def upload_single_video(frame_path):\n",
        "  # Process each frame in the output directory\n",
        "  files = os.listdir(frame_path)\n",
        "  files = sorted(files)  # Sort alphabetically\n",
        "  files_to_upload = []\n",
        "  for file in files:\n",
        "    files_to_upload.append(\n",
        "        File(file_path=os.path.join(frame_path, file),\n",
        "            timestamp_seconds=get_timestamp_seconds(file)))\n",
        "\n",
        "  # Upload the files to the API\n",
        "  uploaded_files = []\n",
        "  print(f'Uploading {len(files_to_upload)} files. This might take a bit...')\n",
        "  for file in files_to_upload:\n",
        "    # print(f'Uploading: {file.file_path}...')\n",
        "    response = genai_service.media().upload(\n",
        "        media_body=file.file_path,\n",
        "        media_mime_type = file.mimetype).execute()\n",
        "    file.set_file_uri(response[\"file\"][\"uri\"])\n",
        "    uploaded_files.append(file)\n",
        "  print(f\"Completed file uploads!\\n\\nUploaded: {len(uploaded_files)} files\")\n",
        "  return uploaded_files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm9L6To8XYbC"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Make GenerateContent Request\n",
        "def makeGenerateContentRequest(prompt, files):\n",
        "  generateContent = {\"contents\": [{ \"parts\": [{ \"text\": prompt }]}]}\n",
        "  for file in files:\n",
        "    generateContent[\"contents\"][0][\"parts\"].extend(makeVideoPart(file))\n",
        "  return generateContent\n",
        "\n",
        "def makeVideoPart(file):\n",
        "  return [\n",
        "      {\"text\": file.timestamp},\n",
        "      {\"file_data\": {\"file_uri\": file.uri, \"mime_type\": file.mimetype }}]\n",
        "\n",
        "def extract_videos(video_ids, frame_path):\n",
        "  # Unzip videos\n",
        "  if not os.path.exists('videos'):\n",
        "    print(\"Unzipping videos.zip ...\")\n",
        "    unzip_command = 'unzip drive/MyDrive/videos.zip -d .'   # change to your own path of TempCompass Videos\n",
        "    os.system(unzip_command)\n",
        "\n",
        "  # Extracting video to frames\n",
        "  for vid in tqdm(video_ids):\n",
        "    vfile = f\"videos/{vid}.mp4\"\n",
        "    extract_frame_from_video(vfile, frame_path)\n",
        "\n",
        "def inference_single_video(prompt, uploaded_files, model=\"models/gemini-1.5-pro-latest\"):\n",
        "  response = genai_service.models().generateContent(\n",
        "      model = model,\n",
        "      body = makeGenerateContentRequest(prompt, uploaded_files)).execute()\n",
        "  print(response)\n",
        "  try:\n",
        "    return response['candidates'][0]['content']['parts'][0]['text']\n",
        "  except:\n",
        "    if str(response)==\"{'promptFeedback': {'blockReason': 'OTHER'}}\" or response['candidates'][0]['finishReason'] == 'SAFETY':\n",
        "      return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWI8wlRUhPMK",
        "outputId": "3f795cd0-4632-4ec7-ca07-8fe8e2eef3e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 410/410 [00:00<00:00, 70061.71it/s]\n",
            "  0%|          | 0/410 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "video_frames/1054717541\n",
            "Uploading 7 files. This might take a bit...\n",
            "{'candidates': [{'content': {'parts': [{'text': '## Analysis of Video and Information\\n\\nBased on the video showing a baker kneading dough with their hands at what appears to be a regular speed, the information consistent with the video is:\\n\\n**Information A: {\\'subject\\': \\'entire video\\', \\'speed\\': \\'at normal speed\\'}** \\n\\nThe video does not display characteristics of slow motion or time-lapse, making options B and C inaccurate.\\n\\n## Suggested Caption\\n\\nConsidering the analysis, a suitable caption for the video could be:\\n\\n**\"A baker expertly kneads dough, preparing it for baking.\"** \\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0, 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE'}]}]}\n",
            "{'candidates': [{'content': {'parts': [{'text': \"## Analysis\\n\\nBased on the video showing a baker kneading dough at a regular pace, the matching information is: \\n\\n**Information A: {'subject': 'entire video', 'speed': 'at normal speed'}** \\n\\nInformation B and C, suggesting slow motion and time-lapse, are not consistent with the video.\\n\\n## Suggested Caption\\n\\nHere are a few caption options based on the analysis:\\n\\n**Option 1 (Simple):** Kneading dough to perfection. \\n\\n**Option 2 (Descriptive):** A baker's skilled hands rhythmically work the dough, transforming it into a future culinary delight.\\n\\n**Option 3 (Engaging):** The art of bread making starts with passionate hands and a simple ball of dough. \\n\"}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0, 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE'}]}]}\n",
            "{'candidates': [{'content': {'parts': [{'text': \"## Video Caption Analysis\\n\\nThe video appears to show hands kneading dough at a normal speed. There is no indication of slow motion or time-lapse effects. \\n\\nTherefore, the information consistent with the video is:\\n\\n**Information A: {'subject': 'entire video', 'speed': 'at normal speed'}**\\n\\n**Suggested Caption:** A baker skillfully kneads dough on a floured surface. \\n\"}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0, 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE'}]}]}\n",
            "{'candidates': [{'content': {'parts': [{'text': '## Video Analysis and Captioning\\n\\nBased on the video, the hands are kneading dough at a normal pace. There is no indication of slow motion or time-lapse effects. \\n\\nTherefore, the information that aligns with the video is:\\n\\n**Information A: {\\'subject\\': \\'entire video\\', \\'speed\\': \\'at normal speed\\'}**\\n\\n**Suggested Caption:**\\n\\n\"Expert hands knead dough with precision and care.\" \\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0, 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE'}]}]}\n",
            "Deleting 7 images. This might take a bit...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  6%|▌         | 24/410 [01:39<26:37,  4.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed deleting files!\n",
            "\n",
            "Deleted: 7 files\n",
            "video_frames/1093041749\n",
            "Uploading 11 files. This might take a bit...\n",
            "{'candidates': [{'content': {'parts': [{'text': \"## Analysis of Video and Information:\\n\\nThe video clearly shows a dragon landing on the ground amidst flames and then breathing fire. \\n\\nTherefore, the information consistent with the video is:\\n\\n**Information B: {'subject': 'dragon', 'order': 'landing from the sky and then breathing fire'}**\\n\\n\\n## Generated Caption:\\n\\n**A fearsome dragon descends from the dark sky, landing amidst a fiery inferno. With a mighty roar, it unleashes a torrent of flames, engulfing the surroundings in a blazing inferno.** \\n\"}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0, 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE'}]}]}\n",
            "{'candidates': [{'content': {'parts': [{'text': '## Analyzing the Video and Information\\n\\nThe video portrays a dragon landing on the ground, followed by it breathing fire. Let\\'s evaluate the provided information:\\n\\n* **Information A:** This describes a dragon flying before breathing fire, which doesn\\'t match the video.\\n* **Information B:** This accurately describes the video\\'s sequence of events: the dragon lands and then breathes fire.\\n* **Information C & D:** Both describe the dragon breathing fire before any movement, which contradicts the video. \\n\\nTherefore, **Information B** aligns with the video content.\\n\\n## Suggested Caption:\\n\\n**\"A majestic dragon descends from the fiery heavens, unleashing its scorching breath upon the land.\"** \\n'}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0, 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE'}]}]}\n",
            "{'candidates': [{'content': {'parts': [{'text': \"## Video Analysis: \\n\\nThe video shows a dragon landing on the ground and then breathing fire. \\n\\n## Consistent Information:\\n\\n**Information B** is consistent with the video: {'subject': 'dragon', 'order': 'landing from the sky and then breathing fire'}. \\n\\n##  Video Caption:\\n\\n**A dragon descends from the sky and unleashes a fiery blast.** \\n\"}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0, 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE'}]}]}\n",
            "{'candidates': [{'content': {'parts': [{'text': \"## Analysis:\\n\\nThe video depicts a dragon landing from the sky and then breathing fire. \\n\\nTherefore, the information that aligns with the video is:\\n\\n**Information B: {'subject': 'dragon', 'order': 'landing from the sky and then breathing fire'}**\\n\\n## Suggested Caption:\\n\\n**A majestic dragon descends, unleashing its fiery breath upon the land.** \\n\"}], 'role': 'model'}, 'finishReason': 'STOP', 'index': 0, 'safetyRatings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE'}]}]}\n",
            "Deleting 11 images. This might take a bit...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 410/410 [03:23<00:00,  2.01it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed deleting files!\n",
            "\n",
            "Deleted: 11 files\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json, time\n",
        "from google.colab import files\n",
        "\n",
        "class MaxTryExceedError(Exception):\n",
        "  def __init__(self, message):\n",
        "    self.message = message\n",
        "\n",
        "# Load questions\n",
        "qtype = 'captioning'\n",
        "question_path = f\"drive/MyDrive/questions/{qtype}.json\"   # change to your own path of TempCompass questions\n",
        "output_path = 'predictions'\n",
        "video_frm_path = 'video_frames'\n",
        "with open(question_path, 'r') as f:\n",
        "  input_datas = json.load(f)\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "  os.makedirs(output_path)\n",
        "pred_file = f\"{output_path}/{qtype}.json\"\n",
        "\n",
        "# Loading existing predictions\n",
        "if os.path.isfile(pred_file):\n",
        "  with open(f\"{output_path}/{qtype}.json\", 'r') as f:\n",
        "      predictions = json.load(f)\n",
        "else:\n",
        "  predictions = {}\n",
        "\n",
        "answer_prompt = {\n",
        "  \"multi-choice\": \"\\nPlease directly give the best option:\",\n",
        "  \"yes_no\": \"\\nPlease answer yes or no:\",\n",
        "  \"caption_matching\": \"\\nPlease directly give the best option:\",\n",
        "  \"captioning\": \"\"    # The answer \"Generated Caption:\" is already contained in the question\n",
        "}\n",
        "\n",
        "extract_videos(list(input_datas.keys()), video_frm_path)\n",
        "\n",
        "# Running inference over the dataset\n",
        "for vid, data in tqdm(input_datas.items()):\n",
        "  if vid not in predictions or len(predictions[vid])!=len(data):\n",
        "    cur_video_frm_path = os.path.join(video_frm_path, vid)\n",
        "    print(cur_video_frm_path)\n",
        "    uploaded_files = upload_single_video(cur_video_frm_path)\n",
        "    if vid not in predictions:\n",
        "      predictions[vid] = {}\n",
        "    for dim, questions in data.items():\n",
        "      if dim in predictions[vid] and len(predictions[vid][dim])==len(questions):\n",
        "        continue\n",
        "      predictions[vid][dim] = []\n",
        "      for question in questions:\n",
        "        prompt = question['question'] + answer_prompt[qtype]\n",
        "        max_try = 10\n",
        "        while True:\n",
        "          try:\n",
        "            video_llm_pred = inference_single_video(prompt, uploaded_files)\n",
        "            break\n",
        "          except Exception as e:\n",
        "            print(e)\n",
        "            if max_try<=0:\n",
        "              raise MaxTryExceedError(f\"Max try exceed...\")\n",
        "            max_try -= 1\n",
        "            print(f\"Not success! {max_try} retries remaining...\")\n",
        "            time.sleep(30)\n",
        "        time.sleep(18)\n",
        "        predictions[vid][dim].append({'question': question['question'], 'answer': question['answer'], 'prediction': video_llm_pred})\n",
        "      with open(pred_file, 'w') as f:\n",
        "        json.dump(predictions, f, indent=4)\n",
        "    delete_upload_files(uploaded_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB9Jk6k1a0-C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e72LIOdYhZAo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9Ood531lsjD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
